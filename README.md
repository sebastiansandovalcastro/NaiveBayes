# ğ”¼â„šğ•Œğ•€â„™ğ•† ğŸ± - â„•ğ”¸ğ•€ğ•ğ”¼ ğ”¹ğ”¸ğ•ğ”¼ğ•Š

<div align="center">

**TECNOLÃ“GICO NACIONAL DE MÃ‰XIO**

INSTITUTO TECNOLÃ“GICO DE TIJUANA

SUBDIRECCIÃ“N ACADÃ‰MICA
 
DEPARTAMENTO DE SISTEMAS Y COMPUTACIÃ“N
 
SEMESTRE SEPTIEMBRE 2020 â€“ ENERO 2021

INGENIERÃA EN SISTEMAS COMPUTACIONALES

 
 [![](https://upload.wikimedia.org/wikipedia/commons/2/2e/ITT.jpg)](https://upload.wikimedia.org/wikipedia/commons/2/2e/ITT.jpg)

**PROFESOR**

JOSÃ‰ CHRISTIAN ROMERO HERNÃNDEZ

**CLASE**

DATOS MASIVOS
BDD-1704 SC9A, L - V 18:00 - 19:00 (91L4/0308)


**NAIVE BAYES**


**EQUIPO 8:**

PACHECO RAMÃREZ HUGO ANDRÃ‰S	16210790

RAMIREZ GONZALEZ MARCO ANTONIO 15212341

ROBLES ACOSTA JOSE FRANCISCO 16212368

SANDOVAL CASTRO SEBASTIÃN	16212076


Tijuana, Baja California, al 07 de diciembre de 2020.
â€ƒ
</div>

# ğ”»ğ”¼ğ•Šğ”¸â„â„ğ•†ğ•ƒğ•ƒğ•†

## ğŸ’¥ IntroducciÃ³n

_El presente documento estÃ¡ diseÃ±ado especialmente para mostrar el desarrollo del tema **Naive Bayes**, abarcando desde conceptos generales y ecuaciones necesarias hasta una implementaciÃ³n prÃ¡ctica en una situaciÃ³n real y su aplicaciÃ³n mediante codigo **scala**. Finalmente se incluyen algunas ventajas y desventajas al momento de implementar el algoritmo, asÃ­ como una conclusiÃ³n general basada en el anÃ¡lisis resultante a lo largo del desarrollo del documento._

## ğŸ“• Definiciones

ğŸ“‹ _**Algoritmo:** es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, tÃ­picamente, solucionar un problema, realizar un cÃ³mputo, procesar datos y llevar a cabo otras tareas o actividades._ [[1]](https://es.wikipedia.org/wiki/Algoritmo)

ğŸ‘¾ _**Machine Learning:** es una disciplina cientÃ­fica del Ã¡mbito de la Inteligencia Artificial que crea sistemas que aprenden automÃ¡ticamente. Aprender en este contexto quiere decir identificar patrones complejos en millones de datos. La mÃ¡quina que realmente aprende es un algoritmo que revisa los datos y es capaz de predecir comportamientos futuros. AutomÃ¡ticamente, tambiÃ©n en este contexto, implica que estos sistemas se mejoran de forma autÃ³noma con el tiempo, sin intervenciÃ³n humana._ [[2]](https://cleverdata.io/que-es-machine-learning-big-data/)

## ğŸ“– TeorÃ­a

### â“ - Â¿QuÃ© es el algoritmo Naive Bayes?

_**Naive Bayes**_ es una clase especial de algoritmo de clasificaciÃ³n de _**Machine Learning**_. Se encuentra basado en una tÃ©cnica de clasificaciÃ³n estadÃ­stica llamada _**teorema de Bayes**_.

### â“ - Â¿Por quÃ© el algoritmo Naive Bayes se llama de esa forma?

Primeramente, _**Naive Bayes**_ se traduce literalmente como _**Bayes Ingenuo**_, lo que provoca cuestionarse: Â¿por quÃ© ingenuo?

En este algoritmo se asume que las variables predictoras son independientes entre sÃ­, lo que quiere decir que la presencia de una cierta caracterÃ­stica en un conjunto de datos no estÃ¡ en absoluto relacionada con la presencia de cualquier otra caracterÃ­stica.

En otras palabras, este tipo de algoritmo trata a sus variables de forma separada, ignorando por completo toda regla de relaciÃ³n que pueda llegar a existir como, por ejemplo, cierto orden lÃ³gico, cierta estructura, alguna caracterÃ­stica en especial, etc.

### â“ - Â¿Para quÃ© se utiliza el algoritmo Naive Bayes?

El algoritmo _**Naive Bayes**_ se utiliza para construir modelos con comportamientos muy buenos. Se hace de una forma mÃ¡s fÃ¡cil debido a la simplicidad del mismo.

El algoritmo consigue hacer esto ya que proporciona una forma de calcular la probabilidad _**posterior**_ de que ocurra un cierto evento _**A**_, dadas algunas probabilidades de eventos _**anteriores**_.

## ğŸ“‹ Algoritmo

### ğŸ”£ EcuaciÃ³n

> P(A | R) = P(R | A) P(A) / P(R)

![ecuacion.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/ecuacion.png)

### ğŸ“œ Pasos de uso

Se recomienda utilizar los siguientes cuatro pasos al momento de implementar el algoritmo _**Naive Bayes**_ en problemas de clasificaciÃ³n:

1. Convertir el conjunto de datos en una tabla de frecuencias.

2. Crear una tabla de probabilidad calculando las correspondientes a que ocurran los diversos eventos.

3. Utilizar la ecuaciÃ³n _**Naive Bayes**_ para calcular la probabilidad posterior de cada clase.

4. Seleccionar la clase con la _**probabilidad posterior mÃ¡s alta**_ como resultado de la predicciÃ³n.

## ğŸ“ Ejemplo teÃ³rico

_Presentaremos los conceptos principales del algoritmo Naive Bayes estudiando el siguiente ejemplo:_

###  ğŸ‘« Alicia, Bruno y la chaqueta roja (ejemplo 1)

Consideremos el caso de dos personas que trabajan en la misma oficina: Alicia y Bruno.
Sabemos que:

- Alicia viene a la oficina 3 dÃ­as a la semana.
- Bruno viene a la oficina 1 dÃ­a a la semana.

_(Esta serÃ­a nuestra informaciÃ³n **anterior**)._

Estamos en la oficina y vemos pasar delante de nosotros a alguien muy rÃ¡pido, tan rÃ¡pido que no sabemos si es Alicia o Bruno.

Dada la informaciÃ³n que tenemos hasta ahora y asumiendo que solo trabajan 4 dÃ­as a la semana, las probabilidades de que la persona vista sea Alicia o Bruno, son:

- P(Alicia) = 3/4 = 0.75
- P(Bruno) = 1/4 = 0.25

Cuando vimos a la persona pasar, vimos que Ã©l o ella llevaba una chaqueta roja. TambiÃ©n sabemos lo siguiente:

- Alicia viste de rojo 2 veces a la semana.
- Bruno viste de rojo 3 veces a la semana.

AsÃ­ que, para cada semana de trabajo, que tiene cinco dÃ­as, podemos inferir lo siguiente:

- La probabilidad de que Alicia vista de rojo es â†’ P(Rojo|Alicia) = 2/5 = 0.4
- La probabilidad de que Bruno vista de rojo â†’ P(Rojo|Bruno) = 3/5 = 0.6

Entonces, con esta informaciÃ³n, Â¿a quiÃ©n vimos pasar? (en forma de probabilidad)

_(Esta nueva probabilidad serÃ¡ la informaciÃ³n **posterior**.)_

Inicialmente conocÃ­amos las probabilidades P(Alicia) y P(Bruno), y despuÃ©s inferÃ­amos las probabilidades de P(Rojo|Alicia) y P(Rojo|Bruno), de forma que las probabilidades reales son:

![probabilidades1.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/probabilidades1.png)

Donde, formalmente, el grÃ¡fico previo se verÃ­a de la siguiente manera:

![probabilidades2.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/probabilidades2.png)

### ğŸ“« Correo normal y correo spam (ejemplo 2)

Hacer click [aquÃ­](https://youtu.be/O2L2Uv9pdDA?t=67) para ver el ejemplo desarrollado en un vÃ­deo de YouTube.

## ğŸ’» Ejemplo prÃ¡ctico

_Presentaremos los conceptos principales del algoritmo Naive Bayes estudiando el siguiente ejemplo:_

### ğŸ”¢ Sample libsvm data

```scala
//Importaciones necesarias.
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
```

![1.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/1.png)

```scala
// Cargar los datos guardados en formato LIBSVM como un DataFrame.
val data = spark.read.format("libsvm").load("C:/Users/Sebas/Desktop/sample_libsvm_data.txt")
data.show(2)
```

![2.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/2.png)

```scala
//Separar los datos en sets de entrenamiento y de prueba (30% reservado para pruebas)
val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3), seed = 1234L)
```

![3.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/3.png)

```scala
// Entrenar un modelo Naive Bayes.
val model = new NaiveBayes().fit(trainingData)
```

![4.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/4.png)

```scala
// Seleccionar las filas de ejemplo a mostrar.
val predictions = model.transform(testData)
predictions.show()
```

![5.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/5.png)

```scala
// Selecciona (prediccion, etiqueta de cierto) y calcular errores de prueba
val evaluator = new MulticlassClassificationEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("accuracy")

val accuracy = evaluator.evaluate(predictions)

println(s"Test set accuracy = $accuracy")
```

![6.png](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/imagenes/6.png)

### ğŸ“‚ CÃ³digo completo

```scala
//Importaciones necesarias.
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator

// Cargar los datos guardados en formato LIBSVM como un DataFrame.
val data = spark.read.format("libsvm").load("C:/Users/Sebas/Desktop/sample_libsvm_data.txt")
data.show(2)

//Separar los datos en sets de entrenamiento y de prueba (30% reservado para pruebas)
val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3), seed = 1234L)

// Entrenar un modelo Naive Bayes.
val model = new NaiveBayes().fit(trainingData)

// Seleccionar las filas de ejemplo a mostrar.
val predictions = model.transform(testData)
predictions.show()

// Selecciona (prediccion, etiqueta de cierto) y calcular errores de prueba
val evaluator = new MulticlassClassificationEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("accuracy")

val accuracy = evaluator.evaluate(predictions)

println(s"Test set accuracy = $accuracy")
```

Hacer click [aquÃ­](https://raw.github.com/sebastiansandovalcastro/NaiveBayes/main/scala/Exposicion.scala) para una mejor visualizaciÃ³n del cÃ³digo scala.

## ğŸ­ Ventajas y Desventajas

### ğŸ‘ Ventajas

- Es una forma fÃ¡cil y rÃ¡pida de predecir clases para problemas de clasificaciÃ³n binarios y multiclase.

- En casos donde existe presunciÃ³n de independencia, el algoritmo se comporta mejor que otros modelos de clasificaciÃ³n, incluso con menos datos de entrenamiento.

- Cada distribuciÃ³n puede ser estimada independientemente como si tuviera una sola dimensiÃ³n, ayudando con problemas derivados de la dimensionalidad y mejorando el rendimiento.

### ğŸ‘ Desventajas

- Conocidos constantemente como pobres estimadores, por lo que no se suelen tomar muy en serio las probabilidades obtenidas.

- La presunciÃ³n de independencia _**Naive**_ muy probablemente no reflejarÃ¡ cÃ³mo son los datos en el mundo real.

- Cuando el conjunto de datos de prueba tiene una caracterÃ­stica que no ha sido observada en el conjunto de entrenamiento, el modelo le asignarÃ¡ una probabilidad de cero y serÃ¡ inÃºtil realizar predicciones.

## ğŸ”¬ Conclusiones

Como conclusiones podemos decir que, una de las mayores ventajas que _**Naive Bayes**_ tiene sobre otros algoritmos de clasificaciÃ³n, es que tiene una gran capacidad para manejar un gran nÃºmero de variantes gracias al uso independiente que estas mismas reciben. El algoritmo se comporta bien incluso ante la presencia de caracterÃ­sticas irrelevantes y no es relativamente afectado por ellas.

Se puede decir que la magia de este algoritmo se encuentra en su simplicidad, ya que _**Naive Bayes**_ funciona bien desde el principio y ajustar sus parÃ¡metros es raramente necesario, ademÃ¡s de que su modelo de entrenamiento y procesos de predicciÃ³n es muy rÃ¡pido teniendo en cuenta la cantidad de datos que puede manejar.

Por Ãºltimo, a pesar de que las probabilidades obtenidas no se suelen tomar bastante en serio debido a la ignorancia que presenta el algoritmo sobre las caracterÃ­sticas que puedan tener las variantes utilizadas, es una vÃ­a muy Ãºtil cuando se busca obtener probabilidades de forma rÃ¡pida y sencilla.

## ğŸ“š Fuentes de informaciÃ³n

- [[1]](https://es.wikipedia.org/wiki/Algoritmo) **Algoritmo** - Wikipedia
- [[2]](https://cleverdata.io/que-es-machine-learning-big-data/) **Â¿QuÃ© es Machine Learning?** - Cleverdata (AndrÃ©s GonzÃ¡lez)
- [[3]](https://www.youtube.com/watch?v=O2L2Uv9pdDA) **Naive Bayes, Clearly Explained!!!** - YouTube ([StatQuest with Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw))
- [[4]](https://medium.com/datos-y-ciencia/algoritmos-naive-bayes-fudamentos-e-implementaci%C3%B3n-4bcb24b307f) **Algoritmos Naive Bayes: Fundamentos e ImplementaciÃ³n** - Medium ([Victor Roman](https://medium.com/@rromanss23))

##  âœï¸ Autores

- **PACHECO RAMÃREZ HUGO ANDRÃ‰S** - _16210790_ - [PachecoHugo](https://github.com/PachecoHugo)
- **RAMIREZ GONZALEZ MARCO ANTONIO** - _15212341_ - [MarcoAnRamirez](https://github.com/MarcoAnRamirez)
- **ROBLES ACOSTA JOSE FRANCISCO** - _16212368_ - [JFranciscoRobles](https://github.com/JFranciscoRobles)
- **SANDOVAL CASTRO SEBASTIÃN** - _16212076_ - [sebastiansandovalcastro](https://github.com/sebastiansandovalcastro)

_[Lista de contribuyentes](https://github.com/sebastiansandovalcastro/NaiveBayes/contributors) que participaron en la elaboraciÃ³n de este documento._
